{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97baa430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "937cad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price day ahead', 'price actual'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset completo com preços, geração, load, e clima\n",
    "df = pd.read_csv(\"dataset.csv\", parse_dates=['time'])\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "# Verifica se a coluna de preço está presente\n",
    "print(df.columns[df.columns.str.contains(\"price\", case=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd49b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_and_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['lag_1h'] = df['price actual'].shift(1)\n",
    "    df['lag_24h'] = df['price actual'].shift(24)\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    return df.dropna()\n",
    "\n",
    "df_prepared = add_lag_and_time_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cf4d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janela 1:\n",
      "  Treino: 2015-01-01 → 2015-12-31  (8737 registos)\n",
      "  Teste:  2016-01-01 → 2016-12-31  (8784 registos)\n",
      "\n",
      "Janela 2:\n",
      "  Treino: 2016-01-01 → 2016-12-31  (8784 registos)\n",
      "  Teste:  2017-01-01 → 2017-12-31  (8760 registos)\n",
      "\n",
      "Janela 3:\n",
      "  Treino: 2017-01-01 → 2017-12-31  (8760 registos)\n",
      "  Teste:  2018-01-01 → 2018-12-31  (8759 registos)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_fixed_yearly_splits(df):\n",
    "    \"\"\"\n",
    "    Cria 3 janelas fixas com treino e teste de 1 ano cada.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_index()\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    ranges = [\n",
    "        ('2015-01-01', '2015-12-31', '2016-01-01', '2016-12-31'),\n",
    "        ('2016-01-01', '2016-12-31', '2017-01-01', '2017-12-31'),\n",
    "        ('2017-01-01', '2017-12-31', '2018-01-01', '2018-12-31')\n",
    "    ]\n",
    "\n",
    "    for train_start, train_end, test_start, test_end in ranges:\n",
    "        df_train = df.loc[train_start:train_end]\n",
    "        df_test = df.loc[test_start:test_end]\n",
    "        splits.append((df_train, df_test))\n",
    "\n",
    "    return splits\n",
    "\n",
    "splits = create_fixed_yearly_splits(df_prepared)\n",
    "\n",
    "# Visualizar os períodos\n",
    "for i, (train, test) in enumerate(splits, start=1):\n",
    "    print(f\"Janela {i}:\")\n",
    "    print(f\"  Treino: {train.index.min().date()} → {train.index.max().date()}  ({len(train)} registos)\")\n",
    "    print(f\"  Teste:  {test.index.min().date()} → {test.index.max().date()}  ({len(test)} registos)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c0a96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 168\n",
    "df_prepared['target'] = df_prepared['price actual'].shift(-forecast_horizon)\n",
    "df_prepared = df_prepared.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e64bbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_across_splits(splits, model_type='lr', forecast_horizon=168):\n",
    "    \"\"\"\n",
    "    Avalia um modelo em 3 janelas com várias métricas.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i, (df_train, df_test) in enumerate(splits, start=1):\n",
    "        # Prepara features e target\n",
    "        df_train = df_train.copy()\n",
    "        df_test = df_test.copy()\n",
    "\n",
    "        df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "        df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "\n",
    "        df_train.dropna(subset=['target'], inplace=True)\n",
    "        df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "        drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "        feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "        X_train = df_train[feature_cols].values\n",
    "        y_train = df_train['target'].values\n",
    "        X_test = df_test[feature_cols].values\n",
    "        y_test = df_test['target'].values\n",
    "\n",
    "        # Escolher o scaler adequado\n",
    "        if model_type == 'lstm':\n",
    "            scaler_X = MinMaxScaler()\n",
    "            scaler_y = MinMaxScaler()\n",
    "        else:\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "\n",
    "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "        y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Escolher o modelo\n",
    "        if model_type == 'lr':\n",
    "            model = LinearRegression()\n",
    "        elif model_type == 'rf':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'xgb':\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Modelo não suportado.\")\n",
    "\n",
    "        model.fit(X_train_scaled, y_train_scaled)\n",
    "        y_pred_scaled = model.predict(X_test_scaled)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "        rmae = mae / np.mean(np.abs(y_test))\n",
    "\n",
    "        results.append({\n",
    "            'janela': i,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'rMAE': rmae\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5335f669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>janela</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.799471</td>\n",
       "      <td>16.629015</td>\n",
       "      <td>40.197175</td>\n",
       "      <td>0.289723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.405461</td>\n",
       "      <td>8.755751</td>\n",
       "      <td>11.368923</td>\n",
       "      <td>0.108381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.545475</td>\n",
       "      <td>8.949137</td>\n",
       "      <td>13.109144</td>\n",
       "      <td>0.102603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   janela        MAE       RMSE   MAPE (%)      rMAE\n",
       "0       1  13.799471  16.629015  40.197175  0.289723\n",
       "1       2   6.405461   8.755751  11.368923  0.108381\n",
       "2       3   6.545475   8.949137  13.109144  0.102603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>janela</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.776209</td>\n",
       "      <td>15.513166</td>\n",
       "      <td>36.386887</td>\n",
       "      <td>0.268239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.992934</td>\n",
       "      <td>8.234128</td>\n",
       "      <td>11.166853</td>\n",
       "      <td>0.101401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.231624</td>\n",
       "      <td>9.724990</td>\n",
       "      <td>14.202488</td>\n",
       "      <td>0.113358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   janela        MAE       RMSE   MAPE (%)      rMAE\n",
       "0       1  12.776209  15.513166  36.386887  0.268239\n",
       "1       2   5.992934   8.234128  11.166853  0.101401\n",
       "2       3   7.231624   9.724990  14.202488  0.113358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>janela</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.779714</td>\n",
       "      <td>15.581631</td>\n",
       "      <td>37.805272</td>\n",
       "      <td>0.268313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.519287</td>\n",
       "      <td>8.851344</td>\n",
       "      <td>11.669757</td>\n",
       "      <td>0.110307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.016541</td>\n",
       "      <td>8.420669</td>\n",
       "      <td>12.197772</td>\n",
       "      <td>0.094312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   janela        MAE       RMSE   MAPE (%)      rMAE\n",
       "0       1  12.779714  15.581631  37.805272  0.268313\n",
       "1       2   6.519287   8.851344  11.669757  0.110307\n",
       "2       3   6.016541   8.420669  12.197772  0.094312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_results = evaluate_model_across_splits(splits, model_type='xgb', forecast_horizon=168)\n",
    "\n",
    "import pandas as pd\n",
    "df_xgb = pd.DataFrame(xgb_results)\n",
    "display(df_xgb)\n",
    "\n",
    "# Linear Regression\n",
    "lr_results = evaluate_model_across_splits(splits, model_type='lr', forecast_horizon=168)\n",
    "df_lr = pd.DataFrame(lr_results)\n",
    "display(df_lr)\n",
    "\n",
    "# Random Forest\n",
    "rf_results = evaluate_model_across_splits(splits, model_type='rf', forecast_horizon=168)\n",
    "df_rf = pd.DataFrame(rf_results)\n",
    "display(df_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f59b13f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>8.387829</td>\n",
       "      <td>10.916625</td>\n",
       "      <td>20.517570</td>\n",
       "      <td>0.156755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>8.439006</td>\n",
       "      <td>10.955887</td>\n",
       "      <td>20.551324</td>\n",
       "      <td>0.157656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>8.396766</td>\n",
       "      <td>10.914608</td>\n",
       "      <td>20.523251</td>\n",
       "      <td>0.156926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>8.442393</td>\n",
       "      <td>10.953486</td>\n",
       "      <td>20.563549</td>\n",
       "      <td>0.157782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth       MAE       RMSE   MAPE (%)      rMAE\n",
       "0           100         10  8.387829  10.916625  20.517570  0.156755\n",
       "1           100         20  8.439006  10.955887  20.551324  0.157656\n",
       "2           200         10  8.396766  10.914608  20.523251  0.156926\n",
       "3           200         20  8.442393  10.953486  20.563549  0.157782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def tune_random_forest(splits, forecast_horizon=168):\n",
    "    \"\"\"\n",
    "    Faz tuning leve do Random Forest com base nas 3 janelas fixas.\n",
    "    Testa combinações simples de n_estimators e max_depth.\n",
    "    Retorna tabela com média das métricas por configuração.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20]\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in param_grid['n_estimators']:\n",
    "        for d in param_grid['max_depth']:\n",
    "            maes, mapes, rmses, rmaes = [], [], [], []\n",
    "\n",
    "            for df_train, df_test in splits:\n",
    "                df_train = df_train.copy()\n",
    "                df_test = df_test.copy()\n",
    "\n",
    "                df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "                df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "\n",
    "                df_train.dropna(subset=['target'], inplace=True)\n",
    "                df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "                drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "                feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "                X_train = df_train[feature_cols].values\n",
    "                y_train = df_train['target'].values\n",
    "                X_test = df_test[feature_cols].values\n",
    "                y_test = df_test['target'].values\n",
    "\n",
    "                scaler_X = StandardScaler()\n",
    "                scaler_y = StandardScaler()\n",
    "                X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "                X_test_scaled = scaler_X.transform(X_test)\n",
    "                y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "                y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "                model = RandomForestRegressor(n_estimators=n, max_depth=d, random_state=42)\n",
    "                model.fit(X_train_scaled, y_train_scaled)\n",
    "                y_pred_scaled = model.predict(X_test_scaled)\n",
    "                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "                rmae = mae / np.mean(np.abs(y_test))\n",
    "\n",
    "                maes.append(mae)\n",
    "                rmses.append(rmse)\n",
    "                mapes.append(mape)\n",
    "                rmaes.append(rmae)\n",
    "\n",
    "            results.append({\n",
    "                'n_estimators': n,\n",
    "                'max_depth': d,\n",
    "                'MAE': np.mean(maes),\n",
    "                'RMSE': np.mean(rmses),\n",
    "                'MAPE (%)': np.mean(mapes),\n",
    "                'rMAE': np.mean(rmaes)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "rf_tuning_results = tune_random_forest(splits)\n",
    "display(rf_tuning_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3673b125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>8.722027</td>\n",
       "      <td>11.259110</td>\n",
       "      <td>21.283755</td>\n",
       "      <td>0.163511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>8.710895</td>\n",
       "      <td>11.261533</td>\n",
       "      <td>21.152055</td>\n",
       "      <td>0.162746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>8.916803</td>\n",
       "      <td>11.444635</td>\n",
       "      <td>21.558414</td>\n",
       "      <td>0.166902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.969084</td>\n",
       "      <td>11.520602</td>\n",
       "      <td>21.760450</td>\n",
       "      <td>0.167809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>8.848607</td>\n",
       "      <td>11.380299</td>\n",
       "      <td>21.531782</td>\n",
       "      <td>0.165876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>8.753945</td>\n",
       "      <td>11.311040</td>\n",
       "      <td>21.223589</td>\n",
       "      <td>0.163460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>9.048125</td>\n",
       "      <td>11.571811</td>\n",
       "      <td>21.755141</td>\n",
       "      <td>0.169110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.991113</td>\n",
       "      <td>11.542660</td>\n",
       "      <td>21.781495</td>\n",
       "      <td>0.168119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  max_depth       MAE       RMSE   MAPE (%)  \\\n",
       "0           100           0.05          6  8.722027  11.259110  21.283755   \n",
       "1           100           0.05          8  8.710895  11.261533  21.152055   \n",
       "2           100           0.10          6  8.916803  11.444635  21.558414   \n",
       "3           100           0.10          8  8.969084  11.520602  21.760450   \n",
       "4           200           0.05          6  8.848607  11.380299  21.531782   \n",
       "5           200           0.05          8  8.753945  11.311040  21.223589   \n",
       "6           200           0.10          6  9.048125  11.571811  21.755141   \n",
       "7           200           0.10          8  8.991113  11.542660  21.781495   \n",
       "\n",
       "       rMAE  \n",
       "0  0.163511  \n",
       "1  0.162746  \n",
       "2  0.166902  \n",
       "3  0.167809  \n",
       "4  0.165876  \n",
       "5  0.163460  \n",
       "6  0.169110  \n",
       "7  0.168119  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def tune_xgboost(splits, forecast_horizon=168):\n",
    "    \"\"\"\n",
    "    Faz tuning leve do XGBoost com base nas 3 janelas fixas.\n",
    "    Retorna média das métricas por combinação de hiperparâmetros.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [6, 8]\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in param_grid['n_estimators']:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for d in param_grid['max_depth']:\n",
    "                maes, mapes, rmses, rmaes = [], [], [], []\n",
    "\n",
    "                for df_train, df_test in splits:\n",
    "                    df_train = df_train.copy()\n",
    "                    df_test = df_test.copy()\n",
    "\n",
    "                    df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "                    df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "\n",
    "                    df_train.dropna(subset=['target'], inplace=True)\n",
    "                    df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "                    drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "                    feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "                    X_train = df_train[feature_cols].values\n",
    "                    y_train = df_train['target'].values\n",
    "                    X_test = df_test[feature_cols].values\n",
    "                    y_test = df_test['target'].values\n",
    "\n",
    "                    scaler_X = StandardScaler()\n",
    "                    scaler_y = StandardScaler()\n",
    "                    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "                    X_test_scaled = scaler_X.transform(X_test)\n",
    "                    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "                    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "                    model = XGBRegressor(n_estimators=n, learning_rate=lr, max_depth=d, random_state=42)\n",
    "                    model.fit(X_train_scaled, y_train_scaled)\n",
    "                    y_pred_scaled = model.predict(X_test_scaled)\n",
    "                    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "                    rmae = mae / np.mean(np.abs(y_test))\n",
    "\n",
    "                    maes.append(mae)\n",
    "                    rmses.append(rmse)\n",
    "                    mapes.append(mape)\n",
    "                    rmaes.append(rmae)\n",
    "\n",
    "                results.append({\n",
    "                    'n_estimators': n,\n",
    "                    'learning_rate': lr,\n",
    "                    'max_depth': d,\n",
    "                    'MAE': np.mean(maes),\n",
    "                    'RMSE': np.mean(rmses),\n",
    "                    'MAPE (%)': np.mean(mapes),\n",
    "                    'rMAE': np.mean(rmaes)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "xgb_tuning_results = tune_xgboost(splits)\n",
    "display(xgb_tuning_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbebeb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>janela</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15.412731</td>\n",
       "      <td>17.965089</td>\n",
       "      <td>42.907639</td>\n",
       "      <td>0.323514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.120766</td>\n",
       "      <td>10.451350</td>\n",
       "      <td>14.269063</td>\n",
       "      <td>0.137457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.859065</td>\n",
       "      <td>13.083367</td>\n",
       "      <td>18.931895</td>\n",
       "      <td>0.170273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   janela        MAE       RMSE   MAPE (%)      rMAE\n",
       "0       1  15.412731  17.965089  42.907639  0.323514\n",
       "1       2   8.120766  10.451350  14.269063  0.137457\n",
       "2       3  10.859065  13.083367  18.931895  0.170273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def evaluate_lstm_on_splits(splits, forecast_horizon=168, timesteps=24, units=50, batch_size=32, epochs=10):\n",
    "    results = []\n",
    "\n",
    "    for i, (df_train, df_test) in enumerate(splits, start=1):\n",
    "        df_train = df_train.copy()\n",
    "        df_test = df_test.copy()\n",
    "\n",
    "        df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "        df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "\n",
    "        df_train.dropna(subset=['target'], inplace=True)\n",
    "        df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "        drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "        feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "        X_train = df_train[feature_cols].values\n",
    "        y_train = df_train['target'].values\n",
    "        X_test = df_test[feature_cols].values\n",
    "        y_test = df_test['target'].values\n",
    "\n",
    "        # Normalização com MinMaxScaler\n",
    "        scaler_X = MinMaxScaler()\n",
    "        scaler_y = MinMaxScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "        y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Criação das sequências para LSTM\n",
    "        def build_sequences(X, y, timesteps):\n",
    "            Xs, ys = [], []\n",
    "            for i in range(timesteps, len(X)):\n",
    "                Xs.append(X[i - timesteps:i])\n",
    "                ys.append(y[i])\n",
    "            return np.array(Xs), np.array(ys)\n",
    "\n",
    "        X_train_seq, y_train_seq = build_sequences(X_train_scaled, y_train_scaled, timesteps)\n",
    "        X_test_seq, y_test_seq = build_sequences(X_test_scaled, y_test_scaled, timesteps)\n",
    "\n",
    "        # Modelo LSTM\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units, activation='relu', input_shape=(timesteps, X_train_seq.shape[2])))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train_seq, y_train_seq, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        y_pred_scaled = model.predict(X_test_seq).ravel()\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "        y_test_real = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Métricas\n",
    "        mae = mean_absolute_error(y_test_real, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_real, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test_real, y_pred) * 100\n",
    "        rmae = mae / np.mean(np.abs(y_test_real))\n",
    "\n",
    "        results.append({\n",
    "            'janela': i,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'rMAE': rmae\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "lstm_results = evaluate_lstm_on_splits(splits, forecast_horizon=168)\n",
    "df_lstm = pd.DataFrame(lstm_results)\n",
    "display(df_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4276fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>rMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>10.127373</td>\n",
       "      <td>12.504681</td>\n",
       "      <td>22.996347</td>\n",
       "      <td>0.186857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>11.335515</td>\n",
       "      <td>14.056716</td>\n",
       "      <td>26.302912</td>\n",
       "      <td>0.210037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>10.697724</td>\n",
       "      <td>13.173039</td>\n",
       "      <td>25.055857</td>\n",
       "      <td>0.199013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>11.384304</td>\n",
       "      <td>14.023839</td>\n",
       "      <td>26.369113</td>\n",
       "      <td>0.212262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  batch_size        MAE       RMSE   MAPE (%)      rMAE\n",
       "0     50          16  10.127373  12.504681  22.996347  0.186857\n",
       "1     50          32  11.335515  14.056716  26.302912  0.210037\n",
       "2    100          16  10.697724  13.173039  25.055857  0.199013\n",
       "3    100          32  11.384304  14.023839  26.369113  0.212262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tune_lstm(splits, forecast_horizon=168, timesteps=24, epochs=10):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "\n",
    "    param_grid = {\n",
    "        'units': [50, 100],\n",
    "        'batch_size': [16, 32]\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for units in param_grid['units']:\n",
    "        for batch_size in param_grid['batch_size']:\n",
    "            maes, mapes, rmses, rmaes = [], [], [], []\n",
    "\n",
    "            for df_train, df_test in splits:\n",
    "                df_train = df_train.copy()\n",
    "                df_test = df_test.copy()\n",
    "\n",
    "                df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "                df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "\n",
    "                df_train.dropna(subset=['target'], inplace=True)\n",
    "                df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "                drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "                feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "                X_train = df_train[feature_cols].values\n",
    "                y_train = df_train['target'].values\n",
    "                X_test = df_test[feature_cols].values\n",
    "                y_test = df_test['target'].values\n",
    "\n",
    "                scaler_X = MinMaxScaler()\n",
    "                scaler_y = MinMaxScaler()\n",
    "                X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "                X_test_scaled = scaler_X.transform(X_test)\n",
    "                y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "                y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "                # Sequências\n",
    "                def build_sequences(X, y, timesteps):\n",
    "                    Xs, ys = [], []\n",
    "                    for i in range(timesteps, len(X)):\n",
    "                        Xs.append(X[i - timesteps:i])\n",
    "                        ys.append(y[i])\n",
    "                    return np.array(Xs), np.array(ys)\n",
    "\n",
    "                X_train_seq, y_train_seq = build_sequences(X_train_scaled, y_train_scaled, timesteps)\n",
    "                X_test_seq, y_test_seq = build_sequences(X_test_scaled, y_test_scaled, timesteps)\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(units, activation='relu', input_shape=(timesteps, X_train_seq.shape[2])))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(optimizer='adam', loss='mse')\n",
    "                model.fit(X_train_seq, y_train_seq, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                y_pred_scaled = model.predict(X_test_seq).ravel()\n",
    "                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "                y_test_real = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).ravel()\n",
    "\n",
    "                mae = mean_absolute_error(y_test_real, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test_real, y_pred))\n",
    "                mape = mean_absolute_percentage_error(y_test_real, y_pred) * 100\n",
    "                rmae = mae / np.mean(np.abs(y_test_real))\n",
    "\n",
    "                maes.append(mae)\n",
    "                rmses.append(rmse)\n",
    "                mapes.append(mape)\n",
    "                rmaes.append(rmae)\n",
    "\n",
    "            results.append({\n",
    "                'units': units,\n",
    "                'batch_size': batch_size,\n",
    "                'MAE': np.mean(maes),\n",
    "                'RMSE': np.mean(rmses),\n",
    "                'MAPE (%)': np.mean(mapes),\n",
    "                'rMAE': np.mean(rmaes)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "lstm_tuning_results = tune_lstm(splits)\n",
    "display(lstm_tuning_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f13630ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpere\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "📊 Diebold-Mariano Statistic: 38.9308\n",
      "📌 p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Função do teste (como antes)\n",
    "def diebold_mariano_manual(e1, e2, h=1):\n",
    "    d = e1 - e2\n",
    "    d_mean = np.mean(d)\n",
    "    d_var = np.var(d, ddof=1)\n",
    "    n = len(d)\n",
    "    DM_stat = d_mean / np.sqrt(d_var / n)\n",
    "    from scipy.stats import t\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(DM_stat), df=n - 1))\n",
    "    return DM_stat, p_value\n",
    "\n",
    "# ============\n",
    "# PREPARAÇÃO\n",
    "# ============\n",
    "df_train, df_test = splits[2]  # Janela 3\n",
    "df_train = df_train.copy()\n",
    "df_test = df_test.copy()\n",
    "forecast_horizon = 168\n",
    "\n",
    "df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "df_test['target'] = df_test['price actual'].shift(-forecast_horizon)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].values\n",
    "y_train = df_train['target'].values\n",
    "X_test = df_test[feature_cols].values\n",
    "y_test = df_test['target'].values\n",
    "\n",
    "# ============\n",
    "# XGBOOST\n",
    "# ============\n",
    "scaler_X_xgb = StandardScaler()\n",
    "scaler_y_xgb = StandardScaler()\n",
    "X_train_xgb = scaler_X_xgb.fit_transform(X_train)\n",
    "X_test_xgb = scaler_X_xgb.transform(X_test)\n",
    "y_train_xgb = scaler_y_xgb.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "model_xgb.fit(X_train_xgb, y_train_xgb)\n",
    "y_pred_xgb_scaled = model_xgb.predict(X_test_xgb)\n",
    "y_pred_xgb = scaler_y_xgb.inverse_transform(y_pred_xgb_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# ============\n",
    "# LSTM\n",
    "# ============\n",
    "scaler_X_lstm = MinMaxScaler()\n",
    "scaler_y_lstm = MinMaxScaler()\n",
    "X_train_lstm = scaler_X_lstm.fit_transform(X_train)\n",
    "X_test_lstm = scaler_X_lstm.transform(X_test)\n",
    "y_train_lstm = scaler_y_lstm.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Função para criar sequências\n",
    "def build_sequences(X, y, timesteps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(timesteps, len(X)):\n",
    "        Xs.append(X[i - timesteps:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_train_seq, y_train_seq = build_sequences(X_train_lstm, y_train_lstm, timesteps=24)\n",
    "X_test_seq, y_test_seq = build_sequences(X_test_lstm, scaler_y_lstm.transform(y_test.reshape(-1, 1)).ravel(), timesteps=24)\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', input_shape=(24, X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "y_pred_lstm_scaled = model_lstm.predict(X_test_seq).ravel()\n",
    "y_pred_lstm = scaler_y_lstm.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).ravel()\n",
    "y_true = scaler_y_lstm.inverse_transform(y_test_seq.reshape(-1, 1)).ravel()\n",
    "\n",
    "# ============\n",
    "# DIEBOLD-MARIANO TEST\n",
    "# ============\n",
    "e_xgb = np.abs(y_true - y_pred_xgb[-len(y_true):])  # alinhar tamanhos\n",
    "e_lstm = np.abs(y_true - y_pred_lstm)\n",
    "\n",
    "dm_stat, p_val = diebold_mariano_manual(e_lstm, e_xgb, h=1)\n",
    "print(f\"📊 Diebold-Mariano Statistic: {dm_stat:.4f}\")\n",
    "print(f\"📌 p-value: {p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6ac83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Diebold-Mariano Statistic (RF vs XGB): -3.4012\n",
      "📌 p-value: 0.0007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# ============\n",
    "# RANDOM FOREST\n",
    "# ============\n",
    "scaler_X_rf = StandardScaler()\n",
    "scaler_y_rf = StandardScaler()\n",
    "\n",
    "X_train_rf = scaler_X_rf.fit_transform(X_train)\n",
    "X_test_rf = scaler_X_rf.transform(X_test)\n",
    "y_train_rf = scaler_y_rf.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "model_rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "y_pred_rf_scaled = model_rf.predict(X_test_rf)\n",
    "y_pred_rf = scaler_y_rf.inverse_transform(y_pred_rf_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Alinhar y_true com y_pred_rf\n",
    "y_true_rf = scaler_y_rf.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "# ============\n",
    "# DIEBOLD–MARIANO: RF vs XGBoost\n",
    "# ============\n",
    "# Alinhar tamanhos (caso necessário)\n",
    "min_len = min(len(y_true_rf), len(y_pred_xgb))\n",
    "\n",
    "e_rf = np.abs(y_true_rf[-min_len:] - y_pred_rf[-min_len:])\n",
    "e_xgb = np.abs(y_true_rf[-min_len:] - y_pred_xgb[-min_len:])\n",
    "\n",
    "dm_stat, p_val = diebold_mariano_manual(e_rf, e_xgb, h=1)\n",
    "\n",
    "print(f\"📊 Diebold-Mariano Statistic (RF vs XGB): {dm_stat:.4f}\")\n",
    "print(f\"📌 p-value: {p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39141ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Treinar o modelo com os dados disponíveis\u001b[39;00m\n\u001b[0;32m      7\u001b[0m xgb_model_long \u001b[38;5;241m=\u001b[39m XGBRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m xgb_model_long\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_X\u001b[49m, train_y)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Preparar a sequência mais recente\u001b[39;00m\n\u001b[0;32m     11\u001b[0m forecast_168h \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preparar treino a partir da Janela 3\n",
    "df_train, df_test = splits[2]  # Janela 3\n",
    "df_train = df_train.copy()\n",
    "\n",
    "# Criar target com 168h (7 dias)\n",
    "forecast_horizon = 168\n",
    "df_train['target'] = df_train['price actual'].shift(-forecast_horizon)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "# Selecionar features\n",
    "drop_cols = ['price actual', 'price day ahead', 'target']\n",
    "feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "train_X = df_train[feature_cols].values\n",
    "train_y = df_train['target'].values\n",
    "\n",
    "# Escalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "train_X = scaler_X.fit_transform(train_X)\n",
    "train_y = scaler_y.fit_transform(train_y.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Treinar o modelo com os dados disponíveis\n",
    "xgb_model_long = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model_long.fit(train_X, train_y)\n",
    "\n",
    "latest_input = df_test[-24:].copy()\n",
    "\n",
    "# Preparar a sequência mais recente\n",
    "forecast_168h = []\n",
    "current_input = latest_input.copy()\n",
    "\n",
    "for step in range(168):\n",
    "    # Escalar e prever a próxima hora\n",
    "    input_scaled = scaler_X.transform(current_input[feature_cols])\n",
    "    pred_scaled = xgb_model_long.predict(input_scaled[-1:])\n",
    "    pred_real = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()[0]\n",
    "    forecast_168h.append(pred_real)\n",
    "\n",
    "    # Atualizar linha seguinte com novos valores\n",
    "    next_row = current_input.iloc[-1:].copy()\n",
    "    next_row['lag_1h'] = pred_real\n",
    "    next_row['lag_24h'] = current_input.iloc[-24]['lag_1h'] if 'lag_1h' in current_input.columns else np.nan\n",
    "\n",
    "    # Atualizar variáveis temporais\n",
    "    next_row['hour'] = (next_row['hour'] + 1) % 24\n",
    "    next_row['hour_sin'] = np.sin(2 * np.pi * next_row['hour'] / 24)\n",
    "    next_row['hour_cos'] = np.cos(2 * np.pi * next_row['hour'] / 24)\n",
    "    next_row['day_of_week'] = (next_row['day_of_week'] + (next_row['hour'] == 0).astype(int)) % 7\n",
    "    next_row['dow_sin'] = np.sin(2 * np.pi * next_row['day_of_week'] / 7)\n",
    "    next_row['dow_cos'] = np.cos(2 * np.pi * next_row['day_of_week'] / 7)\n",
    "\n",
    "    # Atualizar sequência\n",
    "    current_input = pd.concat([current_input.iloc[1:], next_row])\n",
    "\n",
    "# Plot do resultado\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(range(1, 169), forecast_168h, marker='o', label='XGBoost Forecast')\n",
    "plt.title(\"XGBoost Forecast — Next 7 Days (168h Horizon)\")\n",
    "plt.xlabel(\"Hour Ahead\")\n",
    "plt.ylabel(\"Forecasted Price (€/MWh)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
